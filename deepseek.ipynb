{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please install OpenAI SDK first: `pip3 install openai`\n",
    "# !pip3 install openai\n",
    "# %pip install openai\n",
    "\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import time\n",
    "\n",
    "client = OpenAI(api_key=\"sk-9157cd146a344095baf8e3ef6454117b\", base_url=\"https://api.deepseek.com\")\n",
    "chatHistory = [{\"inputTask\": \" \", \"response\": \" \"}]\n",
    "terminalExecutionHistory = [{\"icommand\": \" \", \"response\": \" \"}]\n",
    "feedbackHistory = [{\"human feedback\":\" \"}]\n",
    "\n",
    "def logComputationToFile(logMessage):\n",
    "    # This function logs the message to the log file\n",
    "    # It takes a log file name and a log message as input\n",
    "    # and appends the message to the log file.\n",
    "    with open(\"taskagent.log\", 'a') as f:\n",
    "        f.write(time.asctime() + \" : \" + logMessage + \"\\n\")\n",
    "        f.close()\n",
    "\n",
    "\n",
    "def getSubTaskList(inputTask=\"Say Hello\"):\n",
    "    # This function generates a list of sub tasks for a given task\n",
    "    # returns a list of tasks if task can be broken down\n",
    "    # into subtasks, else returns an empty list.\n",
    "    logComputationToFile(\"Generating sub task list for the task: \" + inputTask)\n",
    "    #convert the chatHIstory list to a string\n",
    "    \n",
    "    chatHistoryString = \"\"\n",
    "    for i in range(len(chatHistory)):\n",
    "        chatHistoryString += str(chatHistory[i]) + \"\\n\" \n",
    "    \n",
    "    feedbackHistoryString = \"\"\n",
    "    for i in range(len(chatHistory)):\n",
    "        feedbackHistoryString += str(chatHistory[i]) + \"\\n\" \n",
    "\n",
    "\n",
    "    sysRole =  \"\"\"You are a function that takes one task as input. You already have access to a linux terminal with basic commands.\n",
    "    The definition of an atomic task as a task that can be run by a one line linux shell command on the terminal.\n",
    "    If the inputted task can be broken down into a list of modular subtasks, return a json having the following fields \"atomic\":\"false\" and \"subtasks\":\"<enter the list of subtasks of the inputted task>\". This list should only have the names of subtasks of the inputted task. These names should be a brief description of the task. Break the input into modular tasks.\n",
    "    If the inputted task is an atomic task, only return the json with the following fields \"atomic\":\"true\" and \"command\":\"<enter the linux command to achieve it>\".\n",
    "    Python is already installed on the system. You can use it to run any python code. If a task needs you to install a software package, return a one line command that installs the package. Do not check if it is in the system or not. Just return the command to install it since it is an atomic task.\n",
    "    When you have to write into a file, use the linux command \"printf\" to write into the file. Do not use any other command to write into a file.\n",
    "    When trying to run a python file, use the command \"python3 <filename>\" to run the file. Do not use any other command to run the file.\n",
    "    The following is the chat history: \"\"\" + chatHistoryString + \" the following is the feedback history \" + feedbackHistoryString\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": sysRole},\n",
    "            {\"role\": \"user\", \"content\": \"The input task is :\" + inputTask},\n",
    "        ],\n",
    "        stream=False\n",
    "    )\n",
    "\n",
    "    chatHistory.append({\"inputTask\": inputTask, \"response\": response.choices[0].message.content})\n",
    "    logComputationToFile(\"Response from the API: \" + response.choices[0].message.content)\n",
    "    jsonform = json.loads(response.choices[0].message.content.replace(\"```json\", \"\").replace(\"```\", \"\"))\n",
    "    # logComputationToFile(\"Parsed JSON: \" + str(jsonform))\n",
    "    return jsonform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m response \u001b[39m=\u001b[39m getSubTaskList(\u001b[39m\"\u001b[39;49m\u001b[39mcreate a pythonscrypt to print hello world on a gui\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[2], line 48\u001b[0m, in \u001b[0;36mgetSubTaskList\u001b[1;34m(inputTask)\u001b[0m\n\u001b[0;32m     36\u001b[0m     feedbackHistoryString \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(chatHistory[i]) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m \n\u001b[0;32m     39\u001b[0m sysRole \u001b[39m=\u001b[39m  \u001b[39m\"\"\"\u001b[39m\u001b[39mYou are a function that takes one task as input. You already have access to a linux terminal with basic commands.\u001b[39m\n\u001b[0;32m     40\u001b[0m \u001b[39mThe definition of an atomic task as a task that can be run by a one line linux shell command on the terminal.\u001b[39m\n\u001b[0;32m     41\u001b[0m \u001b[39mIf the inputted task can be broken down into a list of modular subtasks, return a json having the following fields \u001b[39m\u001b[39m\"\u001b[39m\u001b[39matomic\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfalse\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m and \u001b[39m\u001b[39m\"\u001b[39m\u001b[39msubtasks\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m<enter the list of subtasks of the inputted task>\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m. This list should only have the names of subtasks of the inputted task. These names should be a brief description of the task. Break the input into modular tasks.\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[39mWhen trying to run a python file, use the command \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpython3 <filename>\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m to run the file. Do not use any other command to run the file.\u001b[39m\n\u001b[0;32m     46\u001b[0m \u001b[39mThe following is the chat history: \u001b[39m\u001b[39m\"\"\"\u001b[39m \u001b[39m+\u001b[39m chatHistoryString \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m the following is the feedback history \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m feedbackHistoryString\n\u001b[1;32m---> 48\u001b[0m response \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49mchat\u001b[39m.\u001b[39;49mcompletions\u001b[39m.\u001b[39;49mcreate(\n\u001b[0;32m     49\u001b[0m     model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdeepseek-chat\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     50\u001b[0m     messages\u001b[39m=\u001b[39;49m[\n\u001b[0;32m     51\u001b[0m         {\u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39msystem\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: sysRole},\n\u001b[0;32m     52\u001b[0m         {\u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mThe input task is :\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m inputTask},\n\u001b[0;32m     53\u001b[0m     ],\n\u001b[0;32m     54\u001b[0m     stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[0;32m     55\u001b[0m )\n\u001b[0;32m     57\u001b[0m chatHistory\u001b[39m.\u001b[39mappend({\u001b[39m\"\u001b[39m\u001b[39minputTask\u001b[39m\u001b[39m\"\u001b[39m: inputTask, \u001b[39m\"\u001b[39m\u001b[39mresponse\u001b[39m\u001b[39m\"\u001b[39m: response\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmessage\u001b[39m.\u001b[39mcontent})\n\u001b[0;32m     58\u001b[0m logComputationToFile(\u001b[39m\"\u001b[39m\u001b[39mResponse from the API: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m response\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmessage\u001b[39m.\u001b[39mcontent)\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\openai\\_utils\\_utils.py:287\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    285\u001b[0m             msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMissing required argument: \u001b[39m\u001b[39m{\u001b[39;00mquote(missing[\u001b[39m0\u001b[39m])\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    286\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 287\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:925\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    882\u001b[0m \u001b[39m@required_args\u001b[39m([\u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m], [\u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m    883\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    884\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    922\u001b[0m     timeout: \u001b[39mfloat\u001b[39m \u001b[39m|\u001b[39m httpx\u001b[39m.\u001b[39mTimeout \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m|\u001b[39m NotGiven \u001b[39m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    923\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ChatCompletion \u001b[39m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m    924\u001b[0m     validate_response_format(response_format)\n\u001b[1;32m--> 925\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_post(\n\u001b[0;32m    926\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39m/chat/completions\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    927\u001b[0m         body\u001b[39m=\u001b[39;49mmaybe_transform(\n\u001b[0;32m    928\u001b[0m             {\n\u001b[0;32m    929\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmessages\u001b[39;49m\u001b[39m\"\u001b[39;49m: messages,\n\u001b[0;32m    930\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m\"\u001b[39;49m: model,\n\u001b[0;32m    931\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39maudio\u001b[39;49m\u001b[39m\"\u001b[39;49m: audio,\n\u001b[0;32m    932\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfrequency_penalty\u001b[39;49m\u001b[39m\"\u001b[39;49m: frequency_penalty,\n\u001b[0;32m    933\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfunction_call\u001b[39;49m\u001b[39m\"\u001b[39;49m: function_call,\n\u001b[0;32m    934\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfunctions\u001b[39;49m\u001b[39m\"\u001b[39;49m: functions,\n\u001b[0;32m    935\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mlogit_bias\u001b[39;49m\u001b[39m\"\u001b[39;49m: logit_bias,\n\u001b[0;32m    936\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mlogprobs\u001b[39;49m\u001b[39m\"\u001b[39;49m: logprobs,\n\u001b[0;32m    937\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmax_completion_tokens\u001b[39;49m\u001b[39m\"\u001b[39;49m: max_completion_tokens,\n\u001b[0;32m    938\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmax_tokens\u001b[39;49m\u001b[39m\"\u001b[39;49m: max_tokens,\n\u001b[0;32m    939\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmetadata\u001b[39;49m\u001b[39m\"\u001b[39;49m: metadata,\n\u001b[0;32m    940\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmodalities\u001b[39;49m\u001b[39m\"\u001b[39;49m: modalities,\n\u001b[0;32m    941\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mn\u001b[39;49m\u001b[39m\"\u001b[39;49m: n,\n\u001b[0;32m    942\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mparallel_tool_calls\u001b[39;49m\u001b[39m\"\u001b[39;49m: parallel_tool_calls,\n\u001b[0;32m    943\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mprediction\u001b[39;49m\u001b[39m\"\u001b[39;49m: prediction,\n\u001b[0;32m    944\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mpresence_penalty\u001b[39;49m\u001b[39m\"\u001b[39;49m: presence_penalty,\n\u001b[0;32m    945\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mreasoning_effort\u001b[39;49m\u001b[39m\"\u001b[39;49m: reasoning_effort,\n\u001b[0;32m    946\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mresponse_format\u001b[39;49m\u001b[39m\"\u001b[39;49m: response_format,\n\u001b[0;32m    947\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mseed\u001b[39;49m\u001b[39m\"\u001b[39;49m: seed,\n\u001b[0;32m    948\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mservice_tier\u001b[39;49m\u001b[39m\"\u001b[39;49m: service_tier,\n\u001b[0;32m    949\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstop\u001b[39;49m\u001b[39m\"\u001b[39;49m: stop,\n\u001b[0;32m    950\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstore\u001b[39;49m\u001b[39m\"\u001b[39;49m: store,\n\u001b[0;32m    951\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstream\u001b[39;49m\u001b[39m\"\u001b[39;49m: stream,\n\u001b[0;32m    952\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstream_options\u001b[39;49m\u001b[39m\"\u001b[39;49m: stream_options,\n\u001b[0;32m    953\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtemperature\u001b[39;49m\u001b[39m\"\u001b[39;49m: temperature,\n\u001b[0;32m    954\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtool_choice\u001b[39;49m\u001b[39m\"\u001b[39;49m: tool_choice,\n\u001b[0;32m    955\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtools\u001b[39;49m\u001b[39m\"\u001b[39;49m: tools,\n\u001b[0;32m    956\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtop_logprobs\u001b[39;49m\u001b[39m\"\u001b[39;49m: top_logprobs,\n\u001b[0;32m    957\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtop_p\u001b[39;49m\u001b[39m\"\u001b[39;49m: top_p,\n\u001b[0;32m    958\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m: user,\n\u001b[0;32m    959\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mweb_search_options\u001b[39;49m\u001b[39m\"\u001b[39;49m: web_search_options,\n\u001b[0;32m    960\u001b[0m             },\n\u001b[0;32m    961\u001b[0m             completion_create_params\u001b[39m.\u001b[39;49mCompletionCreateParamsStreaming\n\u001b[0;32m    962\u001b[0m             \u001b[39mif\u001b[39;49;00m stream\n\u001b[0;32m    963\u001b[0m             \u001b[39melse\u001b[39;49;00m completion_create_params\u001b[39m.\u001b[39;49mCompletionCreateParamsNonStreaming,\n\u001b[0;32m    964\u001b[0m         ),\n\u001b[0;32m    965\u001b[0m         options\u001b[39m=\u001b[39;49mmake_request_options(\n\u001b[0;32m    966\u001b[0m             extra_headers\u001b[39m=\u001b[39;49mextra_headers, extra_query\u001b[39m=\u001b[39;49mextra_query, extra_body\u001b[39m=\u001b[39;49mextra_body, timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[0;32m    967\u001b[0m         ),\n\u001b[0;32m    968\u001b[0m         cast_to\u001b[39m=\u001b[39;49mChatCompletion,\n\u001b[0;32m    969\u001b[0m         stream\u001b[39m=\u001b[39;49mstream \u001b[39mor\u001b[39;49;00m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    970\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mStream[ChatCompletionChunk],\n\u001b[0;32m    971\u001b[0m     )\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\openai\\_base_client.py:1239\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1225\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(\n\u001b[0;32m   1226\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1227\u001b[0m     path: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1234\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1235\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[0;32m   1236\u001b[0m     opts \u001b[39m=\u001b[39m FinalRequestOptions\u001b[39m.\u001b[39mconstruct(\n\u001b[0;32m   1237\u001b[0m         method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m, url\u001b[39m=\u001b[39mpath, json_data\u001b[39m=\u001b[39mbody, files\u001b[39m=\u001b[39mto_httpx_files(files), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions\n\u001b[0;32m   1238\u001b[0m     )\n\u001b[1;32m-> 1239\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(ResponseT, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(cast_to, opts, stream\u001b[39m=\u001b[39;49mstream, stream_cls\u001b[39m=\u001b[39;49mstream_cls))\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\openai\\_base_client.py:969\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m    967\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    968\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 969\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39;49msend(\n\u001b[0;32m    970\u001b[0m         request,\n\u001b[0;32m    971\u001b[0m         stream\u001b[39m=\u001b[39;49mstream \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_should_stream_response_body(request\u001b[39m=\u001b[39;49mrequest),\n\u001b[0;32m    972\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m    973\u001b[0m     )\n\u001b[0;32m    974\u001b[0m \u001b[39mexcept\u001b[39;00m httpx\u001b[39m.\u001b[39mTimeoutException \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    975\u001b[0m     log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mEncountered httpx.TimeoutException\u001b[39m\u001b[39m\"\u001b[39m, exc_info\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\httpx\\_client.py:928\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    926\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m    927\u001b[0m     response\u001b[39m.\u001b[39mclose()\n\u001b[1;32m--> 928\u001b[0m     \u001b[39mraise\u001b[39;00m exc\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\httpx\\_client.py:922\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    920\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    921\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m stream:\n\u001b[1;32m--> 922\u001b[0m         response\u001b[39m.\u001b[39;49mread()\n\u001b[0;32m    924\u001b[0m     \u001b[39mreturn\u001b[39;00m response\n\u001b[0;32m    926\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\httpx\\_models.py:881\u001b[0m, in \u001b[0;36mResponse.read\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    877\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[39mRead and return the response content.\u001b[39;00m\n\u001b[0;32m    879\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    880\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_content\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 881\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content \u001b[39m=\u001b[39m \u001b[39mb\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter_bytes())\n\u001b[0;32m    882\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\httpx\\_models.py:897\u001b[0m, in \u001b[0;36mResponse.iter_bytes\u001b[1;34m(self, chunk_size)\u001b[0m\n\u001b[0;32m    895\u001b[0m chunker \u001b[39m=\u001b[39m ByteChunker(chunk_size\u001b[39m=\u001b[39mchunk_size)\n\u001b[0;32m    896\u001b[0m \u001b[39mwith\u001b[39;00m request_context(request\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_request):\n\u001b[1;32m--> 897\u001b[0m     \u001b[39mfor\u001b[39;00m raw_bytes \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miter_raw():\n\u001b[0;32m    898\u001b[0m         decoded \u001b[39m=\u001b[39m decoder\u001b[39m.\u001b[39mdecode(raw_bytes)\n\u001b[0;32m    899\u001b[0m         \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m chunker\u001b[39m.\u001b[39mdecode(decoded):\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\httpx\\_models.py:951\u001b[0m, in \u001b[0;36mResponse.iter_raw\u001b[1;34m(self, chunk_size)\u001b[0m\n\u001b[0;32m    948\u001b[0m chunker \u001b[39m=\u001b[39m ByteChunker(chunk_size\u001b[39m=\u001b[39mchunk_size)\n\u001b[0;32m    950\u001b[0m \u001b[39mwith\u001b[39;00m request_context(request\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_request):\n\u001b[1;32m--> 951\u001b[0m     \u001b[39mfor\u001b[39;00m raw_stream_bytes \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream:\n\u001b[0;32m    952\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_bytes_downloaded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(raw_stream_bytes)\n\u001b[0;32m    953\u001b[0m         \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m chunker\u001b[39m.\u001b[39mdecode(raw_stream_bytes):\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\httpx\\_client.py:153\u001b[0m, in \u001b[0;36mBoundSyncStream.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m typing\u001b[39m.\u001b[39mIterator[\u001b[39mbytes\u001b[39m]:\n\u001b[1;32m--> 153\u001b[0m     \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stream:\n\u001b[0;32m    154\u001b[0m         \u001b[39myield\u001b[39;00m chunk\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\httpx\\_transports\\default.py:127\u001b[0m, in \u001b[0;36mResponseStream.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m typing\u001b[39m.\u001b[39mIterator[\u001b[39mbytes\u001b[39m]:\n\u001b[0;32m    126\u001b[0m     \u001b[39mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 127\u001b[0m         \u001b[39mfor\u001b[39;00m part \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_httpcore_stream:\n\u001b[0;32m    128\u001b[0m             \u001b[39myield\u001b[39;00m part\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:407\u001b[0m, in \u001b[0;36mPoolByteStream.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m    406\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n\u001b[1;32m--> 407\u001b[0m     \u001b[39mraise\u001b[39;00m exc \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:403\u001b[0m, in \u001b[0;36mPoolByteStream.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m typing\u001b[39m.\u001b[39mIterator[\u001b[39mbytes\u001b[39m]:\n\u001b[0;32m    402\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[39mfor\u001b[39;00m part \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stream:\n\u001b[0;32m    404\u001b[0m             \u001b[39myield\u001b[39;00m part\n\u001b[0;32m    405\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\httpcore\\_sync\\http11.py:342\u001b[0m, in \u001b[0;36mHTTP11ConnectionByteStream.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[39mwith\u001b[39;00m ShieldCancellation():\n\u001b[0;32m    341\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n\u001b[1;32m--> 342\u001b[0m \u001b[39mraise\u001b[39;00m exc\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\httpcore\\_sync\\http11.py:334\u001b[0m, in \u001b[0;36mHTTP11ConnectionByteStream.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    333\u001b[0m     \u001b[39mwith\u001b[39;00m Trace(\u001b[39m\"\u001b[39m\u001b[39mreceive_response_body\u001b[39m\u001b[39m\"\u001b[39m, logger, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_request, kwargs):\n\u001b[1;32m--> 334\u001b[0m         \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_connection\u001b[39m.\u001b[39m_receive_response_body(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    335\u001b[0m             \u001b[39myield\u001b[39;00m chunk\n\u001b[0;32m    336\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m    337\u001b[0m     \u001b[39m# If we get an exception while streaming the response,\u001b[39;00m\n\u001b[0;32m    338\u001b[0m     \u001b[39m# we want to close the response (and possibly the connection)\u001b[39;00m\n\u001b[0;32m    339\u001b[0m     \u001b[39m# before raising that exception.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\httpcore\\_sync\\http11.py:203\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_body\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    200\u001b[0m timeout \u001b[39m=\u001b[39m timeouts\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mread\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    202\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 203\u001b[0m     event \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_receive_event(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    204\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(event, h11\u001b[39m.\u001b[39mData):\n\u001b[0;32m    205\u001b[0m         \u001b[39myield\u001b[39;00m \u001b[39mbytes\u001b[39m(event\u001b[39m.\u001b[39mdata)\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\httpcore\\_sync\\http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    214\u001b[0m     event \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_h11_state\u001b[39m.\u001b[39mnext_event()\n\u001b[0;32m    216\u001b[0m \u001b[39mif\u001b[39;00m event \u001b[39mis\u001b[39;00m h11\u001b[39m.\u001b[39mNEED_DATA:\n\u001b[1;32m--> 217\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_network_stream\u001b[39m.\u001b[39;49mread(\n\u001b[0;32m    218\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mREAD_NUM_BYTES, timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[0;32m    219\u001b[0m     )\n\u001b[0;32m    221\u001b[0m     \u001b[39m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     \u001b[39m#\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[39m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[39m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[0;32m    228\u001b[0m     \u001b[39m# it as a ConnectError.\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39m==\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_h11_state\u001b[39m.\u001b[39mtheir_state \u001b[39m==\u001b[39m h11\u001b[39m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\httpcore\\_backends\\sync.py:128\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[1;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[0;32m    127\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sock\u001b[39m.\u001b[39msettimeout(timeout)\n\u001b[1;32m--> 128\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv(max_bytes)\n",
      "File \u001b[1;32mc:\\python\\Lib\\ssl.py:1263\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[1;34m(self, buflen, flags)\u001b[0m\n\u001b[0;32m   1259\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1260\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1261\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1262\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[1;32m-> 1263\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(buflen)\n\u001b[0;32m   1264\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1265\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[1;32mc:\\python\\Lib\\ssl.py:1136\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m, buffer)\n\u001b[0;32m   1135\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1136\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m)\n\u001b[0;32m   1137\u001b[0m \u001b[39mexcept\u001b[39;00m SSLError \u001b[39mas\u001b[39;00m x:\n\u001b[0;32m   1138\u001b[0m     \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39margs[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m SSL_ERROR_EOF \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "response = getSubTaskList(\"create a pythonscrypt to print hello world on a gui\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to add the following subtasks of the task: build a website than can support the viewing of 3d objects, uploading 3d objects\n",
      "\n",
      "Set up a web server\n",
      "\n",
      "Install necessary software for 3D object handling\n",
      "\n",
      "Create a frontend for viewing 3D objects\n",
      "\n",
      "Implement backend for uploading 3D objects\n",
      "\n",
      "Configure database to store 3D object metadata\n",
      "\n",
      "Deploy the website\n",
      "\n",
      "Give direction on these tasks\n",
      "I want to add the following subtasks of the task: Set up a web server\n",
      "\n",
      "Install a web server software (e.g., Apache, Nginx)\n",
      "\n",
      "Configure the web server\n",
      "\n",
      "Start the web server service\n",
      "\n",
      "Test the web server\n",
      "\n",
      "Give direction on these tasks\n",
      "I want to add the following subtasks of the task: Install a web server software (e.g., Apache, Nginx)\n",
      "\n",
      "Install Apache web server\n",
      "\n",
      "Install Nginx web server\n",
      "\n",
      "Give direction on these tasks\n",
      "I want to add the following subtasks of the task: Configure the web server\n",
      "\n",
      "Edit the web server configuration file\n",
      "\n",
      "Set up virtual hosts (if needed)\n",
      "\n",
      "Configure SSL/TLS for HTTPS\n",
      "\n",
      "Restart the web server to apply changes\n",
      "\n",
      "Give direction on these tasks\n"
     ]
    }
   ],
   "source": [
    "import shellinteractions\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, task:str, level = 99999):\n",
    "        self.task = task\n",
    "        self.parent = False\n",
    "        self.leaf = False\n",
    "        self.level = level\n",
    "        self.humaninput = False\n",
    "        # self.addSubTasks()\n",
    "        self.subTasks = []  # List to store any number of subTasks, or in this case, sub tasks\n",
    "\n",
    "    # def addSubTask(self, subTaskName:str):\n",
    "    #     \"\"\"Add a child node with the given task\"\"\"\n",
    "    #     child_node = Node(subTaskName, level=(self.level + 1))\n",
    "    #     self.subTasks.append(child_node)\n",
    "    #     self.parent = True\n",
    "    #     return child_node\n",
    "    \n",
    "    def addListOfSubtasks(self, listofsubtasks):\n",
    "        logComputationToFile(\"I want to add the following subtasks of the task: \" + self.task)\n",
    "        print(\"I want to add the following subtasks of the task: \" + self.task + \"\\n\")\n",
    "        if len(listofsubtasks) == 0:\n",
    "            return\n",
    "        for task in listofsubtasks:\n",
    "            print(task + \"\\n\")\n",
    "            self.subTasks.append(Node(task, level=(self.level + 1)))\n",
    "        print(\"Give direction on these tasks\")\n",
    "        humaninput = input()\n",
    "        feedbackHistory.append({\"human feedback\": humaninput})\n",
    "        self.parent=True\n",
    "\n",
    "    def fillTreeWithTasks(self):\n",
    "        # logComputationToFile(\"Filling tree w\"/)\n",
    "        # get response from deepseek\n",
    "        response = getSubTaskList(self.task)\n",
    "        \n",
    "        if response[\"atomic\"] == \"false\":\n",
    "            self.addListOfSubtasks(response[\"subtasks\"])\n",
    "            logComputationToFile(\"The task is not atomic, so we need to add the subtasks of the task: \" + self.task)\n",
    "            for childTask in self.subTasks:\n",
    "                childTask.fillTreeWithTasks()\n",
    "        \n",
    "        # if this is an atomic task, then the task is equal to the command line task\n",
    "        if response[\"atomic\"] == \"true\":\n",
    "            self.leaf = True\n",
    "            self.task = response[\"command\"]\n",
    "\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"String representation of the node\"\"\"\n",
    "        return str(self.task)\n",
    "\n",
    "class NaryTree:\n",
    "    def __init__(self, root_task=None):\n",
    "        self.root = Node(root_task) if root_task is not None else None\n",
    "\n",
    "    # def preorder_traversal(self, node=None):\n",
    "    #     \"\"\"Pre-order traversal: root, then subTasks from left to right\"\"\"\n",
    "    #     if node is None and self.root is None:\n",
    "    #         return []\n",
    "        \n",
    "    #     if node is None:\n",
    "    #         node = self.root\n",
    "        \n",
    "    #     result = [node.task]\n",
    "    #     for child in node.subTasks:\n",
    "    #         result.extend(self.preorder_traversal(child))\n",
    "    #     return result\n",
    "\n",
    "    # before visiting a parent node, we need to visit all its subTasks first\n",
    "    def postorder_traversal(self, node=None):\n",
    "        \"\"\"Post-order traversal: subTasks from left to right, then root\"\"\"\n",
    "        if node is None and self.root is None:\n",
    "            return []\n",
    "        \n",
    "        if node is None:\n",
    "            node = self.root\n",
    "        \n",
    "        result = []\n",
    "        if node.parent == True:\n",
    "            for child in node.subTasks:\n",
    "                result.extend(self.postorder_traversal(child))\n",
    "        \n",
    "        if node.parent == False:\n",
    "            result.append(node.task)\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "    # we need level order to visit all nodes and querry deepseek for subtasks of that node\n",
    "    # we can use this to get subtasks of a task\n",
    "    # we start with the main task, which is the root node, and the main goal of the whole operation\n",
    "    # then we get the subtasks of the main task, which are the subTasks of the root node\n",
    "    # then we get the subtasks of the level one subtasks, which are the subTasks of the subTasks of the root node\n",
    "    # then we get subtasks of the level two subtasks, which are the subTasks of the subTasks of the subTasks of the root node\n",
    "    # and so on as long as a node can be broken down into a task, or in another flavour, as long as a node has subTasks\n",
    "    # def level_order_traversal(self):\n",
    "    #     \"\"\"Level-order traversal using a queue\"\"\"\n",
    "    #     if not self.root:\n",
    "    #         return []\n",
    "        \n",
    "    #     result = []\n",
    "    #     queue = [self.root]\n",
    "        \n",
    "    #     while queue:\n",
    "    #         current = queue.pop(0)  # Dequeue\n",
    "    #         result.append(current.task)\n",
    "    #         # Add all subTasks to the queue\n",
    "    #         queue.extend(current.subTasks)\n",
    "        \n",
    "    #     return result\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a tree\n",
    "    rootTask = input(\"What is the task that you want to be computed? \")\n",
    "    tree = NaryTree(root_task=rootTask)\n",
    "    daemon = shellinteractions.ShellInteractions()\n",
    "    tree.root.fillTreeWithTasks()\n",
    "\n",
    "    # Level 1\n",
    "    # child2 = tree.root.addSubTask(\"Stop coding\")\n",
    "    # child3 = tree.root.addSubTask(\"Walk out of the house\")\n",
    "    # child4 = tree.root.addSubTask(\"Walk to the shop\")\n",
    "    \n",
    "    # Level 2\n",
    "    # child2.addSubTask(\"Close the laptop\")\n",
    "    # child2.addSubTask(\"Push chair backwards\")\n",
    "    # child3.addSubTask(\"Rise up from the chair\")\n",
    "    # child3.addSubTask(\"Open the door\")\n",
    "    # child3.addSubTask(\"Walk out the door\")\n",
    "    # child4.addSubTask(\"walk to main door\")\n",
    "    # child4.addSubTask(\"Walk to the shop door\")\n",
    "    # child4.addSubTask(\"Open the shop door\")\n",
    "    # Print traversals\n",
    "    # print(\"Pre-order traversal:\", tree.preorder_traversal())\n",
    "    # Output: [1, 2, 5, 6, 3, 7, 4, 8, 9, 10]\n",
    "    stepsTaken = tree.postorder_traversal()\n",
    "    print(\"Currently executing the tasks:\")\n",
    "    for step in stepsTaken:\n",
    "        logComputationToFile(\"Executing the command: \" + step)\n",
    "        shellexecutionresult = daemon.executeCommand(step)\n",
    "        logComputationToFile(\"The result of the command: \" + shellexecutionresult + \" \\n\")\n",
    "\n",
    "    # Output: [5, 6, 2, 7, 3, 8, 9, 10, 4, 1]\n",
    "    \n",
    "    # print(\"Level-order traversal:\", tree.level_order_traversal())\n",
    "    # Output: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import shellinteractions\n",
    "# Assuming shellinteractions contains a class named ShellInteractions\n",
    "daemon = shellinteractions.ShellInteractions()\n",
    "command = \"printf 'import tkinter as tk\\nroot = tk.Tk()\\nroot.title(\\\"Hello World\\\")\\nlabel = tk.Label(root, text=\\\"Hello World\\\")\\nlabel.pack()\\nroot.mainloop()' > testPrintf.py\"\n",
    "print(daemon.executeCommand(command))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
